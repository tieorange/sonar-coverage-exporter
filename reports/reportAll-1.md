# SonarQube Coverage Rollup ğŸ“ˆ

- ğŸ—‚ï¸ Files analysed: **2**
- ğŸ”¢ Total uncovered lines: **92**
- ğŸ” Total uncovered blocks: **49**
- ğŸ·ï¸ Projects: `praktika_ai_flutter`

## File Overview
| File | Project | Blocks | Lines |
| :---- | :------ | ----: | ----: |
| lib/services/audio/SoundRecorder.dart | praktika_ai_flutter | 33 | 63 |
| lib/services/audio/AudioSettings.dart | praktika_ai_flutter | 16 | 29 |

## Detailed Reports

## ğŸ“„ lib/services/audio/SoundRecorder.dart

- **Project**: praktika_ai_flutter
- **File**: `lib/services/audio/SoundRecorder.dart`
- **Generated**: 10/2/2025, 11:12:13 PM
- **SonarQube page**: https://sonarqube.ops.app.praktika.ai/component_measures?id=Praktika-ai_praktika_ai_flutter_AZFu4DzCGe8rI-Wgisw6&metric=new_coverage&pullRequest=1632&view=list&selected=Praktika-ai_praktika_ai_flutter_AZFu4DzCGe8rI-Wgisw6%3Alib%2Fservices%2Faudio%2FSoundRecorder.dart

### Quick Snapshot ğŸ“Š
- ğŸ”¢ Uncovered new-code lines: **63**
- ğŸ” Blocks captured: **33**
- ğŸ§µ Longest block: lines 248-256 (9 lines)
- ğŸ”¥ Hotspot groups: **11**

#### Range Overview ğŸ—‚ï¸
| Range | Lines | Highlight |
| :---- | ----: | :-------- |
| lines 28-30 | 3 | bool get isStarting => this == starting; |
| lines 62-63 | 2 | loggy.info('[AudioSession] Interruption event: ${event.type.name}. Begin: ${event.begin}'); |
| lines 67-68 | 2 | loggy.info( |
| line 70 | 1 | await AudioSettings.configureRecorder(isForced: true, selectBluetoothInput: true); |
| line 88 | 1 | loggy.info('[SoundRecorder] Recorder initializing started'); |
| lines 90-91 | 2 | status.value = RecorderStatus.starting; |
| line 93 | 1 | _voiceFilePath = null; |
| line 96 | 1 | final isGranted = await _recorder.hasPermission(); |
| lines 98-100 | 3 | status.value = RecorderStatus.initial; |
| line 102 | 1 | loggy.info('[SoundRecorder] Permission is granted'); |
| lines 106-110 | 5 | _stateStreamSubscription = _recorder.onStateChanged().listen((state) { |
| line 114 | 1 | loggy.info('[SoundRecorder] shouldConfigureAudioSettings: $shouldConfigureAudioSettings'); |
| lines 116-118 | 3 | loggy.info('[SoundRecorder] Calling AudioSettings.configureRecorder()'); |
| lines 121-122 | 2 | final results = await Future.wait([ |
| line 134 | 1 | _createVoiceFile().then((sink) => _voiceFileSink = sink), |
| line 137 | 1 | final stream = results.first as Stream<Uint8List>; |
| line 139 | 1 | await _recordCompleter?.future; |
| lines 141-143 | 3 | if (status.value != RecorderStatus.starting) { |
| line 146 | 1 | status.value = RecorderStatus.recording; |
| lines 148-149 | 2 | _dataSubscription = stream.listen((data) { |
| lines 152-153 | 2 | loggy.info('[SoundRecorder] Recorder start completed'); |
| lines 155-157 | 3 | status.value = RecorderStatus.initial; |
| line 162 | 1 | return Result.error(StartRecorderError()); |
| lines 164-165 | 2 | if (_recordCompleter != null && !(_recordCompleter?.isCompleted ?? false)) { |
| line 184 | 1 | status.value = RecorderStatus.stopping; |
| line 187 | 1 | await _stopRecorder(); |
| line 189 | 1 | return _voiceFilePath; |
| line 191 | 1 | loggy.error( |
| lines 198-199 | 2 | await _cancelRecorderStreams(); |
| line 224 | 1 | loggy.error( |
| lines 248-256 | 9 | Future<IOSink> _createVoiceFile() async { |
| line 271 | 1 | loggy.error( |
| line 311 | 1 | loggy.error( |

#### Notable Statements ğŸ“Œ
- ğŸ“Œ lines 28-30 â€“ bool get isStarting => this == starting;
- ğŸ“Œ lines 62-63 â€“ loggy.info('[AudioSession] Interruption event: ${event.type.name}. Begin: ${event.begin}');
- ğŸ“Œ lines 67-68 â€“ loggy.info(
- ğŸ“Œ line 70 â€“ await AudioSettings.configureRecorder(isForced: true, selectBluetoothInput: true);
- ğŸ“Œ line 88 â€“ loggy.info('[SoundRecorder] Recorder initializing started');
- ğŸ“Œ lines 90-91 â€“ status.value = RecorderStatus.starting;
- ğŸ“Œ line 93 â€“ _voiceFilePath = null;
- ğŸ“Œ line 96 â€“ final isGranted = await _recorder.hasPermission();
- ğŸ“Œ lines 98-100 â€“ status.value = RecorderStatus.initial;
- ğŸ“Œ line 102 â€“ loggy.info('[SoundRecorder] Permission is granted');
- ğŸ“Œ lines 106-110 â€“ _stateStreamSubscription = _recorder.onStateChanged().listen((state) {
- ğŸ“Œ line 114 â€“ loggy.info('[SoundRecorder] shouldConfigureAudioSettings: $shouldConfigureAudioSettings');
- ğŸ“Œ lines 116-118 â€“ loggy.info('[SoundRecorder] Calling AudioSettings.configureRecorder()');
- ğŸ“Œ lines 121-122 â€“ final results = await Future.wait([
- ğŸ“Œ line 134 â€“ _createVoiceFile().then((sink) => _voiceFileSink = sink),
- ğŸ“Œ line 137 â€“ final stream = results.first as Stream<Uint8List>;
- ğŸ“Œ line 139 â€“ await _recordCompleter?.future;
- ğŸ“Œ lines 141-143 â€“ if (status.value != RecorderStatus.starting) {
- ğŸ“Œ line 146 â€“ status.value = RecorderStatus.recording;
- ğŸ“Œ lines 148-149 â€“ _dataSubscription = stream.listen((data) {
- ğŸ“Œ lines 152-153 â€“ loggy.info('[SoundRecorder] Recorder start completed');
- ğŸ“Œ lines 155-157 â€“ status.value = RecorderStatus.initial;
- ğŸ“Œ line 162 â€“ return Result.error(StartRecorderError());
- ğŸ“Œ lines 164-165 â€“ if (_recordCompleter != null && !(_recordCompleter?.isCompleted ?? false)) {
- ğŸ“Œ line 184 â€“ status.value = RecorderStatus.stopping;
- ğŸ“Œ line 187 â€“ await _stopRecorder();
- ğŸ“Œ line 189 â€“ return _voiceFilePath;
- ğŸ“Œ line 191 â€“ loggy.error(
- ğŸ“Œ lines 198-199 â€“ await _cancelRecorderStreams();
- ğŸ“Œ line 224 â€“ loggy.error(
- ğŸ“Œ lines 248-256 â€“ Future<IOSink> _createVoiceFile() async {
- ğŸ“Œ line 271 â€“ loggy.error(
- ğŸ“Œ line 311 â€“ loggy.error(

### Coverage Hotspots ğŸ”¥
- ğŸ”¥ lines 28-30 Â· 1 block(s), 3 lines â€“ bool get isStarting => this == starting;
- ğŸ”¥ lines 62-70 Â· 3 block(s), 5 lines â€“ loggy.info('[AudioSession] Interruption event: ${event.type.name}. Begin: ${event.begin}'); â€¦ await AudioSettings.configureRecorder(isForced: true, selectBluetoothInput: true);
- ğŸ”¥ lines 88-122 Â· 10 block(s), 20 lines â€“ loggy.info('[SoundRecorder] Recorder initializing started'); â€¦ final results = await Future.wait([
- ğŸ”¥ lines 134-157 Â· 8 block(s), 14 lines â€“ _createVoiceFile().then((sink) => _voiceFileSink = sink), â€¦ status.value = RecorderStatus.initial;
- ğŸ”¥ lines 162-165 Â· 2 block(s), 3 lines â€“ return Result.error(StartRecorderError()); â€¦ if (_recordCompleter != null && !(_recordCompleter?.isCompleted ?? false)) {
- ğŸ”¥ lines 184-191 Â· 4 block(s), 4 lines â€“ status.value = RecorderStatus.stopping; â€¦ loggy.error(
- ğŸ”¥ lines 198-199 Â· 1 block(s), 2 lines â€“ await _cancelRecorderStreams();
- ğŸ”¥ line 224 Â· 1 block(s), 1 line â€“ loggy.error(
- ğŸ”¥ lines 248-256 Â· 1 block(s), 9 lines â€“ Future<IOSink> _createVoiceFile() async {
- ğŸ”¥ line 271 Â· 1 block(s), 1 line â€“ loggy.error(
- ğŸ”¥ line 311 Â· 1 block(s), 1 line â€“ loggy.error(

### Code Gaps ğŸ”
- lines 28-30
- lines 62-63
- lines 67-68
- line 70
- line 88
- lines 90-91
- line 93
- line 96
- lines 98-100
- line 102
- lines 106-110
- line 114
- lines 116-118
- lines 121-122
- line 134
- line 137
- line 139
- lines 141-143
- line 146
- lines 148-149
- lines 152-153
- lines 155-157
- line 162
- lines 164-165
- line 184
- line 187
- line 189
- line 191
- lines 198-199
- line 224
- lines 248-256
- line 271
- line 311

#### ğŸ”¸ lines 28-30

```dart
28|   bool get isStarting => this == starting;
29|   bool get isStopping => this == stopping;
30|   bool get isCancelling => this == cancelling;
```

#### ğŸ”¸ lines 62-63

```dart
62|       loggy.info('[AudioSession] Interruption event: ${event.type.name}. Begin: ${event.begin}');
63|       AudioSettings.configureRecorder(isForced: true);
```

#### ğŸ”¸ lines 67-68

```dart
67|       loggy.info(
68|         '[AudioSession] Device Changed event. Added: ${event.devicesAdded} Removed: ${event.devicesRemoved}',
```

#### ğŸ”¸ line 70

```dart
70|       await AudioSettings.configureRecorder(isForced: true, selectBluetoothInput: true);
```

#### ğŸ”¸ line 88

```dart
88|     loggy.info('[SoundRecorder] Recorder initializing started');
```

#### ğŸ”¸ lines 90-91

```dart
90|     status.value = RecorderStatus.starting;
91|     _recordCompleter = Completer();
```

#### ğŸ”¸ line 93

```dart
93|     _voiceFilePath = null;
```

#### ğŸ”¸ line 96

```dart
96|       final isGranted = await _recorder.hasPermission();
```

#### ğŸ”¸ lines 98-100

```dart
 98|         status.value = RecorderStatus.initial;
 99|         loggy.warning('[SoundRecorder] Permission is not granted', stacktrace: StackTrace.current);
100|         return Result.error(NoMicPermissionError());
```

#### ğŸ”¸ line 102

```dart
102|         loggy.info('[SoundRecorder] Permission is granted');
```

#### ğŸ”¸ lines 106-110

```dart
106|       _stateStreamSubscription = _recorder.onStateChanged().listen((state) {
107|         if (state == RecordState.record) {
108|           loggy.info('[SoundRecorder] Recording started');
109|           _recordCompleter?.complete();
110|           _cancelStateSubscription();
```

#### ğŸ”¸ line 114

```dart
114|       loggy.info('[SoundRecorder] shouldConfigureAudioSettings: $shouldConfigureAudioSettings');
```

#### ğŸ”¸ lines 116-118

```dart
116|         loggy.info('[SoundRecorder] Calling AudioSettings.configureRecorder()');
117|         await AudioSettings.configureRecorder();
118|         loggy.info('[SoundRecorder] AudioSettings.configureRecorder() completed');
```

#### ğŸ”¸ lines 121-122

```dart
121|       final results = await Future.wait([
122|         _recorder.startStream(
```

#### ğŸ”¸ line 134

```dart
134|         _createVoiceFile().then((sink) => _voiceFileSink = sink),
```

#### ğŸ”¸ line 137

```dart
137|       final stream = results.first as Stream<Uint8List>;
```

#### ğŸ”¸ line 139

```dart
139|       await _recordCompleter?.future;
```

#### ğŸ”¸ lines 141-143

```dart
141|       if (status.value != RecorderStatus.starting) {
142|         loggy.info('[SoundRecorder] Recording started, but status is ${status.value}');
143|         return Result.error(CanceledRecorderError());
```

#### ğŸ”¸ line 146

```dart
146|       status.value = RecorderStatus.recording;
```

#### ğŸ”¸ lines 148-149

```dart
148|       _dataSubscription = stream.listen((data) {
149|         _voiceFileSink?.add(data);
```

#### ğŸ”¸ lines 152-153

```dart
152|       loggy.info('[SoundRecorder] Recorder start completed');
153|       return Result.success(stream);
```

#### ğŸ”¸ lines 155-157

```dart
155|       status.value = RecorderStatus.initial;
156|       await _cancelRecorderStreams();
157|       loggy.error(
```

#### ğŸ”¸ line 162

```dart
162|       return Result.error(StartRecorderError());
```

#### ğŸ”¸ lines 164-165

```dart
164|       if (_recordCompleter != null && !(_recordCompleter?.isCompleted ?? false)) {
165|         _recordCompleter?.completeError('Failed to start');
```

#### ğŸ”¸ line 184

```dart
184|     status.value = RecorderStatus.stopping;
```

#### ğŸ”¸ line 187

```dart
187|       await _stopRecorder();
```

#### ğŸ”¸ line 189

```dart
189|       return _voiceFilePath;
```

#### ğŸ”¸ line 191

```dart
191|       loggy.error(
```

#### ğŸ”¸ lines 198-199

```dart
198|       await _cancelRecorderStreams();
199|       status.value = RecorderStatus.initial;
```

#### ğŸ”¸ line 224

```dart
224|       loggy.error(
```

#### ğŸ”¸ lines 248-256

```dart
248|   Future<IOSink> _createVoiceFile() async {
249|     final tempDir = await getTemporaryDirectory();
250|     final fileName = const Uuid().v4() + _streamFileExt;
251|     final filepath = join(tempDir.path, _voiceFolderName, fileName);
252|     _voiceFilePath = filepath;
253|     final outputFile = File(filepath);
254|     await CommonUtils.deleteFileIfExists(filepath);
255|     await CommonUtils.createFileIfNotExists(filepath);
256|     return outputFile.openWrite();
```

#### ğŸ”¸ line 271

```dart
271|       loggy.error(
```

#### ğŸ”¸ line 311

```dart
311|       loggy.error(
```

---
### Ready-to-use Prompt ğŸ¤–
```text
You are assisting with increasing automated test coverage based on SonarQube new-code analysis.
Focus on **lib/services/audio/SoundRecorder.dart** within project **praktika_ai_flutter**.
Target the following 33 uncovered block(s):
  * lines 28-30
  * lines 62-63
  * lines 67-68
  * line 70
  * line 88
  * lines 90-91
  * line 93
  * line 96
  * lines 98-100
  * line 102
  * lines 106-110
  * line 114
  * lines 116-118
  * lines 121-122
  * line 134
  * line 137
  * line 139
  * lines 141-143
  * line 146
  * lines 148-149
  * lines 152-153
  * lines 155-157
  * line 162
  * lines 164-165
  * line 184
  * line 187
  * line 189
  * line 191
  * lines 198-199
  * line 224
  * lines 248-256
  * line 271
  * line 311
For each block, propose or implement tests that execute the code paths shown in the snippets above so SonarQube reports full coverage.
```

### Guidance & Constraints ğŸ› ï¸
- Review existing automated tests and documentation for reference patterns.
- Follow the project conventions defined in `.cursorrules`.
- Keep code changes scoped to the impacted areas and their related test suites.
- Deliver concrete test updates or code snippets that measurably improve coverage.


## ğŸ“„ lib/services/audio/AudioSettings.dart

- **Project**: praktika_ai_flutter
- **File**: `lib/services/audio/AudioSettings.dart`
- **Generated**: 10/2/2025, 11:12:15 PM
- **SonarQube page**: https://sonarqube.ops.app.praktika.ai/component_measures?id=Praktika-ai_praktika_ai_flutter_AZFu4DzCGe8rI-Wgisw6&metric=new_coverage&pullRequest=1632&view=list&selected=Praktika-ai_praktika_ai_flutter_AZFu4DzCGe8rI-Wgisw6%3Alib%2Fservices%2Faudio%2FAudioSettings.dart

### Quick Snapshot ğŸ“Š
- ğŸ”¢ Uncovered new-code lines: **29**
- ğŸ” Blocks captured: **16**
- ğŸ§µ Longest block: lines 145-150 (6 lines)
- ğŸ”¥ Hotspot groups: **5**

#### Range Overview ğŸ—‚ï¸
| Range | Lines | Highlight |
| :---- | ----: | :-------- |
| line 63 | 1 | factory AudioSettings._media() => AudioSettings._( |
| line 124 | 1 | final currentInput = await avSession.currentRoute.then((route) => route.inputs.firstOrNull); |
| lines 126-128 | 3 | currentInput?.portType == AVAudioSessionPort.bluetoothHfp \|\| |
| lines 130-131 | 2 | loggy.info( |
| line 135 | 1 | loggy.info('[AudioSession] Bluetooth input already selected, skipping'); |
| line 139 | 1 | final availableInputs = await avSession.availableInputs; |
| lines 141-142 | 2 | loggy.info( |
| lines 145-150 | 6 | final bluetoothInput = availableInputs.cast<AVAudioSessionPortDescription?>().firstWhere( |
| lines 154-155 | 2 | loggy.info( |
| lines 158-161 | 4 | final session = await AudioSession.instance; |
| line 163 | 1 | loggy.info('[AudioSession] Bluetooth input selected and session reactivated'); |
| line 165 | 1 | loggy.info('[AudioSession] No Bluetooth input available'); |
| line 199 | 1 | loggy.error('[AudioSession] Failed configuration', exception: e, stacktrace: sT); |
| line 207 | 1 | loggy.warning('[AudioSession] Failed to activate session', exception: e, stacktrace: sT); |
| line 214 | 1 | await AVAudioSession().setAllowHapticsAndSystemSoundsDuringRecording(true); |
| line 217 | 1 | loggy.error('[AudioSession] Failed to allow haptic', exception: e, stacktrace: sT); |

#### Notable Statements ğŸ“Œ
- ğŸ“Œ line 63 â€“ factory AudioSettings._media() => AudioSettings._(
- ğŸ“Œ line 124 â€“ final currentInput = await avSession.currentRoute.then((route) => route.inputs.firstOrNull);
- ğŸ“Œ lines 126-128 â€“ currentInput?.portType == AVAudioSessionPort.bluetoothHfp ||
- ğŸ“Œ lines 130-131 â€“ loggy.info(
- ğŸ“Œ line 135 â€“ loggy.info('[AudioSession] Bluetooth input already selected, skipping');
- ğŸ“Œ line 139 â€“ final availableInputs = await avSession.availableInputs;
- ğŸ“Œ lines 141-142 â€“ loggy.info(
- ğŸ“Œ lines 145-150 â€“ final bluetoothInput = availableInputs.cast<AVAudioSessionPortDescription?>().firstWhere(
- ğŸ“Œ lines 154-155 â€“ loggy.info(
- ğŸ“Œ lines 158-161 â€“ final session = await AudioSession.instance;
- ğŸ“Œ line 163 â€“ loggy.info('[AudioSession] Bluetooth input selected and session reactivated');
- ğŸ“Œ line 165 â€“ loggy.info('[AudioSession] No Bluetooth input available');
- ğŸ“Œ line 199 â€“ loggy.error('[AudioSession] Failed configuration', exception: e, stacktrace: sT);
- ğŸ“Œ line 207 â€“ loggy.warning('[AudioSession] Failed to activate session', exception: e, stacktrace: sT);
- ğŸ“Œ line 214 â€“ await AVAudioSession().setAllowHapticsAndSystemSoundsDuringRecording(true);
- ğŸ“Œ line 217 â€“ loggy.error('[AudioSession] Failed to allow haptic', exception: e, stacktrace: sT);

### Coverage Hotspots ğŸ”¥
- ğŸ”¥ line 63 Â· 1 block(s), 1 line â€“ factory AudioSettings._media() => AudioSettings._(
- ğŸ”¥ lines 124-165 Â· 11 block(s), 24 lines â€“ final currentInput = await avSession.currentRoute.then((route) => route.inputs.firstOrNull); â€¦ loggy.info('[AudioSession] No Bluetooth input available');
- ğŸ”¥ line 199 Â· 1 block(s), 1 line â€“ loggy.error('[AudioSession] Failed configuration', exception: e, stacktrace: sT);
- ğŸ”¥ line 207 Â· 1 block(s), 1 line â€“ loggy.warning('[AudioSession] Failed to activate session', exception: e, stacktrace: sT);
- ğŸ”¥ lines 214-217 Â· 2 block(s), 2 lines â€“ await AVAudioSession().setAllowHapticsAndSystemSoundsDuringRecording(true); â€¦ loggy.error('[AudioSession] Failed to allow haptic', exception: e, stacktrace: sT);

### Code Gaps ğŸ”
- line 63
- line 124
- lines 126-128
- lines 130-131
- line 135
- line 139
- lines 141-142
- lines 145-150
- lines 154-155
- lines 158-161
- line 163
- line 165
- line 199
- line 207
- line 214
- line 217

#### ğŸ”¸ line 63

```dart
63|   factory AudioSettings._media() => AudioSettings._(
```

#### ğŸ”¸ line 124

```dart
124|       final currentInput = await avSession.currentRoute.then((route) => route.inputs.firstOrNull);
```

#### ğŸ”¸ lines 126-128

```dart
126|           currentInput?.portType == AVAudioSessionPort.bluetoothHfp ||
127|           currentInput?.portType == AVAudioSessionPort.bluetoothA2dp ||
128|           currentInput?.portType == AVAudioSessionPort.bluetoothLe;
```

#### ğŸ”¸ lines 130-131

```dart
130|       loggy.info(
131|         '[AudioSession] Current input: ${currentInput?.portName} (${currentInput?.portType.name}), isBluetooth: $isCurrentInputBluetooth',
```

#### ğŸ”¸ line 135

```dart
135|         loggy.info('[AudioSession] Bluetooth input already selected, skipping');
```

#### ğŸ”¸ line 139

```dart
139|       final availableInputs = await avSession.availableInputs;
```

#### ğŸ”¸ lines 141-142

```dart
141|       loggy.info(
142|         '[AudioSession] Available inputs: ${availableInputs.map((i) => '${i.portName} (${i.portType.name})').join(', ')}',
```

#### ğŸ”¸ lines 145-150

```dart
145|       final bluetoothInput = availableInputs.cast<AVAudioSessionPortDescription?>().firstWhere(
146|         (input) =>
147|             input?.portType == AVAudioSessionPort.bluetoothHfp ||
148|             input?.portType == AVAudioSessionPort.bluetoothA2dp ||
149|             input?.portType == AVAudioSessionPort.bluetoothLe,
150|         orElse: () => null,
```

#### ğŸ”¸ lines 154-155

```dart
154|         loggy.info(
155|           '[AudioSession] Selecting Bluetooth input: ${bluetoothInput.portName} (${bluetoothInput.portType.name})',
```

#### ğŸ”¸ lines 158-161

```dart
158|         final session = await AudioSession.instance;
159|         await session.setActive(false);
160|         await avSession.setPreferredInput(bluetoothInput);
161|         await session.setActive(true);
```

#### ğŸ”¸ line 163

```dart
163|         loggy.info('[AudioSession] Bluetooth input selected and session reactivated');
```

#### ğŸ”¸ line 165

```dart
165|         loggy.info('[AudioSession] No Bluetooth input available');
```

#### ğŸ”¸ line 199

```dart
199|       loggy.error('[AudioSession] Failed configuration', exception: e, stacktrace: sT);
```

#### ğŸ”¸ line 207

```dart
207|       loggy.warning('[AudioSession] Failed to activate session', exception: e, stacktrace: sT);
```

#### ğŸ”¸ line 214

```dart
214|         await AVAudioSession().setAllowHapticsAndSystemSoundsDuringRecording(true);
```

#### ğŸ”¸ line 217

```dart
217|       loggy.error('[AudioSession] Failed to allow haptic', exception: e, stacktrace: sT);
```

---
### Ready-to-use Prompt ğŸ¤–
```text
You are assisting with increasing automated test coverage based on SonarQube new-code analysis.
Focus on **lib/services/audio/AudioSettings.dart** within project **praktika_ai_flutter**.
Target the following 16 uncovered block(s):
  * line 63
  * line 124
  * lines 126-128
  * lines 130-131
  * line 135
  * line 139
  * lines 141-142
  * lines 145-150
  * lines 154-155
  * lines 158-161
  * line 163
  * line 165
  * line 199
  * line 207
  * line 214
  * line 217
For each block, propose or implement tests that execute the code paths shown in the snippets above so SonarQube reports full coverage.
```

### Guidance & Constraints ğŸ› ï¸
- Review existing automated tests and documentation for reference patterns.
- Follow the project conventions defined in `.cursorrules`.
- Keep code changes scoped to the impacted areas and their related test suites.
- Deliver concrete test updates or code snippets that measurably improve coverage.


ğŸš€ Share this bundle with your tooling or teammates to close the coverage gaps efficiently.